{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrvOD02o3HvH"
   },
   "source": [
    "# Домашнее задание 6: классификация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxwj_Iie3HvJ"
   },
   "source": [
    "В этом домашнем задании вам предстоит построить классификатор текстов!\n",
    "\n",
    "Данные мы будем использовать из Kaggle соревнования: https://www.kaggle.com/competitions/nlp-getting-started/data \n",
    "\n",
    "\n",
    "Оттуда надо скачать файл train.csv. На обучающую и тестовую выборки его поделим кодом ниже, менять его не надо!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQVgqLg93HvJ"
   },
   "source": [
    "Мы будем работать с датасетом постов из твиттера. Нам предстоит решать задачу бинарной классификации - определять содержатся ли в твитте информация о настоящей катастрофе/инциденте или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TcjEYh7R3HvK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import  List\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mjwffGiB3HvK"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "v0uUoFTN3HvK",
    "outputId": "0d37d677-a00d-449c-8f86-6f85dce2ef4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "f49NdWY23HvL"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlLemInT3HvL"
   },
   "source": [
    "## Задание 1 (0.5 балла)\n",
    "\n",
    "Выведете на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их пустой строкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "96aJxmkV4105"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       44\n",
       "location    1760\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.fillna('', inplace=True)\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "keyword      17\n",
       "location    773\n",
       "text          0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.fillna('', inplace=True)\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8CPBUal3HvL"
   },
   "source": [
    "## Задание 2 (1 балл)\n",
    "Давайте немного посмотрим на наши данные. Визуализируйте (где явно просят) или выведете информацию о следующем:\n",
    "\n",
    "1. Какое распределение классов в обучающей выборке?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "WvJ_EU9o5BGm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.target.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучающая выборка в целом сбалансированна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f08KScbP5q2y"
   },
   "source": [
    "2. Посмотрите на колонку \"keyword\" - возьмите 10 наиболее встречающихся значений, постройте ступенчатую диаграмму распределения классов в зависимости от значения keyword, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         44\n",
       "damage                   36\n",
       "siren                    35\n",
       "wreckage                 34\n",
       "fatalities               33\n",
       "                         ..\n",
       "rescue                   16\n",
       "epicentre                10\n",
       "radiation%20emergency     7\n",
       "inundation                7\n",
       "threat                    6\n",
       "Name: keyword, Length: 222, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keyword.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый популярный это пропуск, следовательно берем с 1 по 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "WSCb0htu5w_Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['damage',\n",
       " 'siren',\n",
       " 'wreckage',\n",
       " 'fatalities',\n",
       " 'deluge',\n",
       " 'refugees',\n",
       " 'derail',\n",
       " 'fear',\n",
       " 'tsunami',\n",
       " 'fatality']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_keywords = train.keyword.value_counts()[1:11].index.tolist()\n",
    "popular_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "r9wSwm4L9REm",
    "outputId": "3c6827d4-d35f-47ac-c756-6ab4740ed0b9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_data = train[train['keyword'].isin(popular_keywords)]\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.histplot(data=count_data, x=\"keyword\", hue=\"target\", multiple=\"stack\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4al3g9E-P09"
   },
   "source": [
    "**Выводы**: Из полученной диаграммы видим, что наличие слова wreckage явно напрашивается как признак для положительного таргета. Также относятся к положительному классу с нормальной такой вероятностью текста, имеющие ключевые слова: damage, derail, fatalities, refugees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c006nNBP3HvM"
   },
   "source": [
    "## Задание 3 (0.5 балла) \n",
    "\n",
    "В этом задании предлагается объединить все три текстовых столбца в один (просто сконкатенировать cтроки) и убрать столбец с индексом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "GdF9gFmL-c0r",
    "outputId": "ebe008b7-4d0e-4bc2-89f3-60a575c1b1fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>9436</td>\n",
       "      <td>survivors</td>\n",
       "      <td>Marietta, GA</td>\n",
       "      <td>Stemming from my #Cubs talk- the team rosters ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>10203</td>\n",
       "      <td>violent%20storm</td>\n",
       "      <td></td>\n",
       "      <td>If you were the NWS wth a rotating storm w/ a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>3980</td>\n",
       "      <td>devastation</td>\n",
       "      <td>Atlanta g.a.</td>\n",
       "      <td>http://t.co/Gxgm1T3W0J From Devastation to Ela...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          keyword      location  \\\n",
       "6590   9436        survivors  Marietta, GA   \n",
       "7122  10203  violent%20storm                 \n",
       "2769   3980      devastation  Atlanta g.a.   \n",
       "\n",
       "                                                   text  target  \n",
       "6590  Stemming from my #Cubs talk- the team rosters ...       1  \n",
       "7122  If you were the NWS wth a rotating storm w/ a ...       1  \n",
       "2769  http://t.co/Gxgm1T3W0J From Devastation to Ela...       0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[[6590, 7122, 2769]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "lwwJKX_l-eoh"
   },
   "outputs": [],
   "source": [
    "train_new = pd.concat([pd.DataFrame(train.keyword +' ' +train.location + ' ' + train.text, columns=['text']),\n",
    "                       train.target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "jk7P70XX_CpT",
    "outputId": "5cf01b29-8ada-46d7-f7ee-74e7aed37996"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>survivors Marietta, GA Stemming from my #Cubs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>violent%20storm  If you were the NWS wth a rot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>devastation Atlanta g.a. http://t.co/Gxgm1T3W0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "6590  survivors Marietta, GA Stemming from my #Cubs ...       1\n",
       "7122  violent%20storm  If you were the NWS wth a rot...       1\n",
       "2769  devastation Atlanta g.a. http://t.co/Gxgm1T3W0...       0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.loc[[6590, 7122, 2769]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new = pd.concat([pd.DataFrame(test.keyword +' ' +test.location + ' ' + test.text, columns=['text']),\n",
    "                       test.target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3824</th>\n",
       "      <td>first%20responders Los Angeles, CA There's sti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>earthquake Earth 1.9 earthquake occurred 15km ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>hellfire  Beware of your temper and a loose to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>airplane%20accident Lehigh Valley, PA Strict l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>derailed Washington, DC Metro acting chief Jac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "3824  first%20responders Los Angeles, CA There's sti...       0\n",
       "3038  earthquake Earth 1.9 earthquake occurred 15km ...       1\n",
       "4291  hellfire  Beware of your temper and a loose to...       0\n",
       "157   airplane%20accident Lehigh Valley, PA Strict l...       1\n",
       "2415  derailed Washington, DC Metro acting chief Jac...       1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViXdGTxP3HvM"
   },
   "source": [
    "## Задание 4 (0.5 балла)\n",
    "\n",
    "Далее мы будем пока работать только с train частью.\n",
    "\n",
    "1. Предобработайте данные (train часть) с помощью CountVectorizer.\n",
    "2. Какого размера получилась матрица?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oB1MTqUVAbPA"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 16937)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаков получилось дофигища"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4waLlnC3HvM"
   },
   "source": [
    "## Задание 5 (1 балл)\n",
    "\n",
    "В предыдущем пункте у вас должна была получиться достаточно большая матрица.\n",
    "Если вы взгляните на текст, то увидете, что там есть множество специальных символов, ссылок и прочего мусора.\n",
    "\n",
    "Давайте также посмотрим на словарь, который получился в результате построения CountVectorizer, его можно найти в поле vocabulary_ инстанса этого класса. Давайте напишем функцию, которая печает ответы на следующие вопросы:\n",
    "\n",
    "1. Найдите в этом словаре все слова, которые содержат цифры. Сколько таких слов нашлось?\n",
    "\n",
    "2. Найдите все слова, которые содержат символы пунктуации. Сколько таких слов нашлось? \n",
    "\n",
    "3. Сколько хэштегов (токен начинается на #) и упоминаний (токен начинается на @) осталось в словаре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ashes': 1738,\n",
       " '2015': 275,\n",
       " 'australia': 1857,\n",
       " 'ûªs': 16908,\n",
       " 'collapse': 3535,\n",
       " 'at': 1783,\n",
       " 'trent': 15114,\n",
       " 'bridge': 2660,\n",
       " 'among': 1463,\n",
       " 'worst': 16331,\n",
       " 'in': 7616,\n",
       " 'history': 7119,\n",
       " 'england': 5227,\n",
       " 'bundled': 2781,\n",
       " 'out': 10954,\n",
       " 'for': 5963,\n",
       " '60': 666,\n",
       " 'http': 7294,\n",
       " 'co': 3489,\n",
       " 't5trhjuau0': 14406,\n",
       " 'great': 6612,\n",
       " 'michigan': 9680,\n",
       " 'technique': 14552,\n",
       " 'camp': 2946,\n",
       " 'b1g': 1937,\n",
       " 'thanks': 14662,\n",
       " 'to': 14912,\n",
       " 'bmurph1019': 2486,\n",
       " 'hail_youtsey': 6806,\n",
       " 'termn8r13': 14605,\n",
       " 'goblue': 6502,\n",
       " 'wrestleon': 16366,\n",
       " 'oaskgki6qj': 10636,\n",
       " 'cnn': 3482,\n",
       " 'tennessee': 14591,\n",
       " 'movie': 9993,\n",
       " 'theater': 14674,\n",
       " 'shooting': 13398,\n",
       " 'suspect': 14314,\n",
       " 'killed': 8470,\n",
       " 'by': 2841,\n",
       " 'police': 11528,\n",
       " 'di8elzswnr': 4456,\n",
       " 'still': 14061,\n",
       " 'rioting': 12620,\n",
       " 'couple': 3806,\n",
       " 'of': 10692,\n",
       " 'hours': 7255,\n",
       " 'left': 8827,\n",
       " 'until': 15491,\n",
       " 'have': 6912,\n",
       " 'be': 2145,\n",
       " 'up': 15501,\n",
       " 'class': 3408,\n",
       " 'crack': 3841,\n",
       " 'the': 14671,\n",
       " 'path': 11169,\n",
       " 'where': 16122,\n",
       " 'wiped': 16212,\n",
       " 'this': 14755,\n",
       " 'morning': 9942,\n",
       " 'during': 4883,\n",
       " 'beach': 2148,\n",
       " 'run': 12849,\n",
       " 'surface': 14290,\n",
       " 'wounds': 16340,\n",
       " 'on': 10805,\n",
       " 'elbow': 5090,\n",
       " 'and': 1485,\n",
       " 'right': 12604,\n",
       " 'knee': 8533,\n",
       " 'yaqrsximph': 16589,\n",
       " 'experts': 5472,\n",
       " 'france': 6051,\n",
       " 'begin': 2201,\n",
       " 'examining': 5418,\n",
       " 'airplane': 1309,\n",
       " 'debris': 4217,\n",
       " 'found': 6011,\n",
       " 'reunion': 12534,\n",
       " 'island': 7888,\n",
       " 'french': 6089,\n",
       " 'air': 1304,\n",
       " 'accident': 1101,\n",
       " 'tagzbcxfj0': 14429,\n",
       " 'mlb': 9835,\n",
       " 'came': 2936,\n",
       " 'kill': 8469,\n",
       " 'indians': 7656,\n",
       " 'fun': 6164,\n",
       " 'video': 15754,\n",
       " 'smirking': 13653,\n",
       " 'remorseless': 12410,\n",
       " 'pakistani': 11076,\n",
       " 'killer': 8471,\n",
       " 'shows': 13428,\n",
       " 'him': 7096,\n",
       " 'boasting': 2499,\n",
       " 'fpjlwoxklg': 6032,\n",
       " 'johnsontionne': 8162,\n",
       " 'except': 5423,\n",
       " 'idk': 7483,\n",
       " 'them': 14704,\n",
       " 'it': 7901,\n",
       " 'really': 12263,\n",
       " 'burning': 2795,\n",
       " 'destroy': 4392,\n",
       " 'house': 7256,\n",
       " 'officer': 10709,\n",
       " 'wounded': 16339,\n",
       " 'dead': 4192,\n",
       " 'after': 1249,\n",
       " 'exchanging': 5427,\n",
       " 'shots': 13410,\n",
       " 'xxfk4khbiw': 16537,\n",
       " 'friggin': 6112,\n",
       " 'wreck': 16363,\n",
       " 'destiel': 4386,\n",
       " 'sucks': 14209,\n",
       " 'read': 12242,\n",
       " 'vine': 15773,\n",
       " 'description': 4367,\n",
       " 'https': 7295,\n",
       " 'mkx6ux4ozt': 9833,\n",
       " 'sterling': 14045,\n",
       " 'scott': 13108,\n",
       " 'red': 12314,\n",
       " 'carpet': 3043,\n",
       " 'fundraiser': 6167,\n",
       " 'oso': 10931,\n",
       " 'mudslide': 10050,\n",
       " 'ma4ra7atql': 9293,\n",
       " 'cg579wldne': 3173,\n",
       " 'libertarianluke': 8911,\n",
       " 'all': 1382,\n",
       " 'that': 14665,\n",
       " 'honest': 7198,\n",
       " 'if': 7494,\n",
       " 'people': 11259,\n",
       " 'want': 15943,\n",
       " 'go': 6495,\n",
       " 'rampage': 12156,\n",
       " 'let': 8877,\n",
       " 'use': 15558,\n",
       " 'their': 14699,\n",
       " 'own': 11007,\n",
       " 'hands': 6843,\n",
       " 'feet': 5696,\n",
       " 'no': 10426,\n",
       " 'casualties': 3074,\n",
       " '7xglah10zl': 819,\n",
       " 'twelve': 15263,\n",
       " 'feared': 5675,\n",
       " 'ambulance': 1444,\n",
       " 'helicopter': 7006,\n",
       " 'crash': 3856,\n",
       " 'thmblaatzp': 14763,\n",
       " 'got': 6552,\n",
       " 'electrocuted': 5102,\n",
       " 'last': 8731,\n",
       " 'night': 10370,\n",
       " 'work': 16304,\n",
       " 'first': 5817,\n",
       " 'time': 14852,\n",
       " 'my': 10116,\n",
       " 'life': 8923,\n",
       " 'shit': 13383,\n",
       " 'was': 15968,\n",
       " 'weird': 16063,\n",
       " 'some': 13737,\n",
       " 'older': 10781,\n",
       " 'native': 10205,\n",
       " 'australians': 1859,\n",
       " 'believe': 2223,\n",
       " 'oceans': 10671,\n",
       " 'were': 16078,\n",
       " 'created': 3875,\n",
       " 'from': 6119,\n",
       " 'urine': 15537,\n",
       " 'an': 1473,\n",
       " 'angry': 1508,\n",
       " 'god': 6504,\n",
       " 'who': 16140,\n",
       " 'tried': 15132,\n",
       " 'drown': 4818,\n",
       " 'world': 16314,\n",
       " 'architect': 1652,\n",
       " 'behind': 2213,\n",
       " 'kanye': 8337,\n",
       " 'west': 16083,\n",
       " 'volcano': 15840,\n",
       " 'musbik7ejf': 10079,\n",
       " 'india': 7650,\n",
       " 'shud': 13433,\n",
       " 'not': 10481,\n",
       " 'give': 6433,\n",
       " 'any': 1559,\n",
       " 'evidence': 5404,\n",
       " 'pak': 11074,\n",
       " 'they': 14738,\n",
       " 'will': 16172,\n",
       " 'share': 13333,\n",
       " 'with': 16228,\n",
       " 'terrorists': 14616,\n",
       " 'amp': 1465,\n",
       " 'next': 10329,\n",
       " 'attack': 1807,\n",
       " 'oth': 10938,\n",
       " 'contries': 3724,\n",
       " 'qiopbtiuvu': 11979,\n",
       " 'auth': 1861,\n",
       " 'louis': 9150,\n",
       " 'vuitton': 15874,\n",
       " 'brown': 2707,\n",
       " 'saumur': 13031,\n",
       " '35': 418,\n",
       " 'cross': 3919,\n",
       " 'body': 2507,\n",
       " 'shoulder': 13412,\n",
       " 'bag': 1991,\n",
       " 'monogram': 9906,\n",
       " '23': 300,\n",
       " '419': 508,\n",
       " 'full': 6161,\n",
       " 'û_': 16891,\n",
       " 'hcdiwe5flc': 6933,\n",
       " 'zlvebeoavg': 16828,\n",
       " 'episode': 5286,\n",
       " 'trunks': 15180,\n",
       " 'annihilated': 1525,\n",
       " 'freiza': 6087,\n",
       " 'is': 7874,\n",
       " 'cleanest': 3415,\n",
       " 'ever': 5390,\n",
       " 'he': 6942,\n",
       " 'showed': 13424,\n",
       " 'nigga': 10368,\n",
       " 'mercy': 9609,\n",
       " 'roughdeal1': 12771,\n",
       " 'ante': 1543,\n",
       " 'hudhud': 7300,\n",
       " 'cyclone': 4036,\n",
       " 'chandrababu': 3202,\n",
       " 'valle': 15639,\n",
       " 'ne': 10252,\n",
       " 'ga': 6240,\n",
       " 'zhenghxn': 16803,\n",
       " '11': 109,\n",
       " 'eyes': 5520,\n",
       " 'akame': 1324,\n",
       " 'tokyo': 14934,\n",
       " 'ghoul': 6400,\n",
       " 'damn': 4097,\n",
       " 'bloody': 2453,\n",
       " 'dont': 4704,\n",
       " 'dare': 4134,\n",
       " 'watch': 15982,\n",
       " 'rayquazaerk': 12208,\n",
       " 'there': 14719,\n",
       " 'are': 1654,\n",
       " 'christian': 3329,\n",
       " 'sure': 14284,\n",
       " 'but': 2818,\n",
       " 'don': 4694,\n",
       " 'suicide': 14222,\n",
       " 'bombing': 2521,\n",
       " 'employed': 5178,\n",
       " 'often': 10730,\n",
       " 'as': 1724,\n",
       " 'islamic': 7886,\n",
       " 'groups': 6658,\n",
       " 'jackmulholland1': 7976,\n",
       " 'think': 14747,\n",
       " 'also': 1421,\n",
       " 'became': 2172,\n",
       " 'marquis': 9434,\n",
       " 'then': 14711,\n",
       " 'carlos': 3032,\n",
       " 'charlie': 3225,\n",
       " 'finally': 5779,\n",
       " 'dublin': 4850,\n",
       " 'sadly': 12925,\n",
       " 'demolished': 4312,\n",
       " 'surf': 14288,\n",
       " 'hi': 7064,\n",
       " 'waimea': 15913,\n",
       " 'bay': 2109,\n",
       " 'like': 8946,\n",
       " 'or': 10889,\n",
       " 'inundated': 7807,\n",
       " 'surfers': 14291,\n",
       " 'czdw8oowa2': 4048,\n",
       " 'motorcyclist': 9972,\n",
       " 'bicyclist': 2307,\n",
       " 'injured': 7712,\n",
       " 'denver': 4336,\n",
       " 'collision': 3549,\n",
       " 'broadway': 2690,\n",
       " 'zl7ojdaj3u': 16824,\n",
       " 'maryland': 9444,\n",
       " 'mansion': 9387,\n",
       " 'fire': 5799,\n",
       " 'caused': 3098,\n",
       " 'damaged': 4088,\n",
       " 'plug': 11484,\n",
       " 'under': 15423,\n",
       " 'christmas': 3335,\n",
       " 'tree': 15100,\n",
       " 'report': 12446,\n",
       " 'says': 13049,\n",
       " 'into': 7801,\n",
       " 'flames': 5852,\n",
       " 'lkjfabqzb3': 9032,\n",
       " 'you': 16677,\n",
       " 'going': 6512,\n",
       " 'demolish': 4311,\n",
       " 'drake': 4757,\n",
       " 'over': 10980,\n",
       " 'ghostwriting': 6399,\n",
       " 'should': 13411,\n",
       " 'know': 8548,\n",
       " 'rihanna': 12609,\n",
       " 'lives': 9017,\n",
       " 'door': 4708,\n",
       " '1acd4900c1424d1': 213,\n",
       " 'foxnews': 6024,\n",
       " 'one': 10809,\n",
       " 'down': 4728,\n",
       " 'buildings': 2763,\n",
       " 'looting': 9120,\n",
       " 'forest': 5978,\n",
       " 'fires': 5812,\n",
       " 'dying': 4918,\n",
       " 'salmon': 12958,\n",
       " 'act': 1138,\n",
       " 'deny': 4337,\n",
       " 'climate': 3437,\n",
       " 'change': 3203,\n",
       " 'nightmares': 10373,\n",
       " 'here': 7028,\n",
       " 'rbzomwgjee': 12220,\n",
       " 'bcpoli': 2137,\n",
       " 'canpoli': 2981,\n",
       " 'vanpoli': 15655,\n",
       " 'ns1aggfnxz': 10528,\n",
       " 'shoes': 13393,\n",
       " 'asics': 1746,\n",
       " 'gt': 6680,\n",
       " 'ii': 7524,\n",
       " 'super': 14260,\n",
       " 'ronnie': 12743,\n",
       " 'fieg': 5747,\n",
       " 'kith': 8505,\n",
       " 'white': 16135,\n",
       " '3m': 468,\n",
       " 'gel': 6332,\n",
       " 'grey': 6634,\n",
       " 'od250zshfy': 10675,\n",
       " 'airport': 1311,\n",
       " 'get': 6373,\n",
       " 'swallowed': 14326,\n",
       " 'sandstorm': 12992,\n",
       " 'minute': 9770,\n",
       " 'wd9odwjj9l': 16020,\n",
       " 'tweetlikeitsseptember11th2001': 15260,\n",
       " 'those': 14774,\n",
       " 'two': 15273,\n",
       " 'california': 2920,\n",
       " 'oil': 10752,\n",
       " 'spill': 13862,\n",
       " 'might': 9705,\n",
       " 'larger': 8724,\n",
       " 'than': 14657,\n",
       " 'projected': 11759,\n",
       " 'xwxbyhtuzc': 16536,\n",
       " 'wzedxefblg': 16431,\n",
       " 'cartoon': 3053,\n",
       " 'bears': 2156,\n",
       " 'without': 16233,\n",
       " 'we': 16025,\n",
       " 'would': 16335,\n",
       " 'qave': 11951,\n",
       " 'knowlddge': 8550,\n",
       " 'toilet': 14931,\n",
       " 'paper': 11110,\n",
       " '_gaabyx': 1004,\n",
       " 'purple': 11888,\n",
       " 'activist': 1150,\n",
       " 'thought': 14777,\n",
       " 'drought': 4813,\n",
       " 'buffoonmike': 2758,\n",
       " 'knew': 8537,\n",
       " 'mo': 9851,\n",
       " 'doing': 4679,\n",
       " 'much': 10047,\n",
       " 'bite': 2367,\n",
       " 'us': 15542,\n",
       " 'influenced': 7696,\n",
       " 'shitty': 13386,\n",
       " 'staff': 13961,\n",
       " 'injuries': 7714,\n",
       " 'acquisitions': 1133,\n",
       " 'toddstarnes': 14923,\n",
       " 'enjoy': 5233,\n",
       " 'impending': 7591,\n",
       " 'landslide': 8705,\n",
       " 'todd': 14921,\n",
       " 'hehe': 6993,\n",
       " 'look': 9105,\n",
       " 'grizzly': 6646,\n",
       " 'peak': 11233,\n",
       " 'now': 10508,\n",
       " 'looks': 9109,\n",
       " 'beginning': 2203,\n",
       " 'dystopian': 4923,\n",
       " 'apocalypse': 1590,\n",
       " 'ignition': 7510,\n",
       " 'knock': 8543,\n",
       " 'detonation': 4409,\n",
       " 'sensor': 13236,\n",
       " 'senso': 13235,\n",
       " 'standard': 13973,\n",
       " 'ks100': 8594,\n",
       " '7o4lnfbe7k': 811,\n",
       " 'fvzsgjtbew': 6194,\n",
       " 'week': 16054,\n",
       " 'responders': 12494,\n",
       " 'dart': 4145,\n",
       " 'members': 9588,\n",
       " 'participating': 11147,\n",
       " 'four': 6015,\n",
       " 'day': 4171,\n",
       " 'intensive': 7774,\n",
       " 'technical': 14550,\n",
       " 'large': 8723,\n",
       " 'animal': 1510,\n",
       " 'tl93aod3er': 14890,\n",
       " 'lot': 9143,\n",
       " '20': 262,\n",
       " 'tom': 14939,\n",
       " 'clancy': 3404,\n",
       " 'military': 9723,\n",
       " 'mystery': 10132,\n",
       " 'novels': 10506,\n",
       " 'paperback': 11111,\n",
       " 'obix79ncxn': 10642,\n",
       " 'tomclancy': 14943,\n",
       " 'why': 16152,\n",
       " 'drowning': 4820,\n",
       " 'low': 9163,\n",
       " 'self': 13211,\n",
       " 'image': 7568,\n",
       " 'take': 14437,\n",
       " 'quiz': 12046,\n",
       " 'z8r6r3nbtb': 16760,\n",
       " 'namffldh5h': 10178,\n",
       " 'gonna': 6522,\n",
       " 'fight': 5756,\n",
       " 'taylor': 14499,\n",
       " 'soon': 13762,\n",
       " 'wish': 16223,\n",
       " 'could': 3793,\n",
       " 'victoria': 15746,\n",
       " 'secret': 13175,\n",
       " 'front': 6120,\n",
       " 'good': 6523,\n",
       " 'spot': 13893,\n",
       " 'flood': 5891,\n",
       " 'combo': 3568,\n",
       " '53inch': 605,\n",
       " '300w': 397,\n",
       " 'curved': 4003,\n",
       " 'cree': 3885,\n",
       " 'led': 8818,\n",
       " 'light': 8934,\n",
       " 'bar': 2043,\n",
       " '4x4': 578,\n",
       " 'offroad': 10723,\n",
       " 'fog': 5928,\n",
       " 'lamp': 8689,\n",
       " 're': 12229,\n",
       " 'o097vsotxk': 10608,\n",
       " 'i23xy7iejj': 7403,\n",
       " 'severe': 13285,\n",
       " 'weather': 16039,\n",
       " 'bulletin': 2769,\n",
       " 'typhoon': 15298,\n",
       " 'ûï': 16911,\n",
       " 'hannaph': 6851,\n",
       " 'soudelor': 13780,\n",
       " 'tropical': 15156,\n",
       " 'warning': 15957,\n",
       " 'issued': 7898,\n",
       " '00': 0,\n",
       " 'pm': 11492,\n",
       " '06': 19,\n",
       " 'thhjjw51pe': 14741,\n",
       " 'fits': 5825,\n",
       " '01': 6,\n",
       " 'bmw': 2487,\n",
       " '325ci': 411,\n",
       " '5l': 637,\n",
       " 'l6': 8652,\n",
       " 'gbvdnczjou': 6318,\n",
       " 'c211hise0r': 2860,\n",
       " 'around': 1693,\n",
       " '10': 81,\n",
       " 'explosion': 5487,\n",
       " 'chemical': 3255,\n",
       " 'park': 11132,\n",
       " 'western': 16084,\n",
       " 'germany': 6368,\n",
       " 'xbznu0qkvs': 16461,\n",
       " 'soul': 13781,\n",
       " 'food': 5948,\n",
       " 'sound': 13785,\n",
       " 'so': 13696,\n",
       " 'bomb': 2517,\n",
       " 'truth': 15184,\n",
       " 'bejftygjil': 2218,\n",
       " 'news': 10313,\n",
       " 'bbc': 2116,\n",
       " 'islam': 7884,\n",
       " 'isis': 7882,\n",
       " 'terrorism': 14614,\n",
       " 'quran': 12055,\n",
       " 'lies': 8922,\n",
       " 'jlczidz7vu': 8126,\n",
       " 'your': 16686,\n",
       " 'lost': 9142,\n",
       " 'alone': 1409,\n",
       " 'sinking': 13506,\n",
       " 'stone': 14078,\n",
       " 'carry': 3046,\n",
       " 'onå': 10834,\n",
       " 'mylittlepwnies3': 10127,\n",
       " 'early__may': 4961,\n",
       " 'anathemazhiv': 1479,\n",
       " 'tonysandos': 14957,\n",
       " 'which': 16125,\n",
       " 'has': 6891,\n",
       " 'do': 4657,\n",
       " 'lebanon': 8815,\n",
       " '80s': 832,\n",
       " 'iran': 7852,\n",
       " 'hostage': 7242,\n",
       " 'crisis': 3908,\n",
       " 'libya': 8917,\n",
       " 'pan': 11090,\n",
       " 'am': 1432,\n",
       " 'pulls': 11863,\n",
       " 'gun': 6707,\n",
       " 'man': 9370,\n",
       " 'apparent': 1601,\n",
       " 'provocation': 11814,\n",
       " 'lhw4vtbhzg': 8907,\n",
       " 'via': 15733,\n",
       " 'dailykos': 4076,\n",
       " 'train': 15056,\n",
       " 'derailment': 4356,\n",
       " 'patna': 11177,\n",
       " 'casualty': 3075,\n",
       " 'far': 5611,\n",
       " 'indian': 7653,\n",
       " 'express': 5495,\n",
       " 'yh5vetm0yz': 16636,\n",
       " '17wgug8z0m': 180,\n",
       " 'dream': 4772,\n",
       " 'magic': 9324,\n",
       " 'linden': 8967,\n",
       " 'method': 9635,\n",
       " 'lite': 8994,\n",
       " 'version': 15711,\n",
       " 'anxiety': 1558,\n",
       " 'panic': 11099,\n",
       " 'cure': 3993,\n",
       " 'program': 11750,\n",
       " '073izwx0lb': 23,\n",
       " 'lind': 8965,\n",
       " 'okmlagvkjv': 10772,\n",
       " '18': 181,\n",
       " 'bovines': 2572,\n",
       " 'rescued': 12466,\n",
       " 'smugglersåênabbed': 13665,\n",
       " 'e7fn5g5ruu': 4945,\n",
       " 'wwp': 16415,\n",
       " 'serving': 13267,\n",
       " 'more': 9932,\n",
       " '75k': 775,\n",
       " 'veterans': 15718,\n",
       " '52k': 601,\n",
       " 'oif': 10751,\n",
       " 'oef': 10686,\n",
       " 'vets': 15719,\n",
       " 'physical': 11354,\n",
       " 'many': 9390,\n",
       " 'invisible': 7821,\n",
       " 'ones': 10813,\n",
       " 'shhlv4dplz': 13364,\n",
       " 'client': 3433,\n",
       " 'learned': 8806,\n",
       " 'about': 1073,\n",
       " 'economics': 5004,\n",
       " 'south': 13795,\n",
       " 'dakota': 4080,\n",
       " 'dust': 4886,\n",
       " 'storm': 14093,\n",
       " 'did': 4473,\n",
       " 'years': 16609,\n",
       " 'college': 3543,\n",
       " 'hubert': 7299,\n",
       " 'humphrey': 7333,\n",
       " 'cramer': 3849,\n",
       " 'iger': 7502,\n",
       " 'words': 16303,\n",
       " 'wrecked': 16365,\n",
       " 'disney': 4565,\n",
       " 'stock': 14069,\n",
       " 'sf5jdnvdw9': 13297,\n",
       " 'til_now': 14846,\n",
       " 'cnbc': 3478,\n",
       " 'marc_holl': 9398,\n",
       " 'nennicook': 10284,\n",
       " 'aitchkaycee': 1316,\n",
       " 'vixstuart': 15811,\n",
       " 'benjbeckwith': 2249,\n",
       " 'pretty': 11691,\n",
       " 'disaster': 4536,\n",
       " 'gbbo': 6311,\n",
       " 'need': 10265,\n",
       " 'arcade': 1650,\n",
       " 'shooter': 13397,\n",
       " 'fix': 5830,\n",
       " 'cte': 3961,\n",
       " 'empty': 5182,\n",
       " 'only': 10823,\n",
       " 'running': 12855,\n",
       " 'obliteration': 10651,\n",
       " 'even': 5384,\n",
       " 'buy': 2829,\n",
       " 'cod': 3508,\n",
       " 'title': 14877,\n",
       " 'weren': 16079,\n",
       " 'overpriced': 10988,\n",
       " 'steam': 14029,\n",
       " 'firepower': 5811,\n",
       " 'lab': 8665,\n",
       " 'electronic': 5103,\n",
       " 'resource': 12486,\n",
       " 'automation': 1873,\n",
       " 'against': 1263,\n",
       " 'infectious': 7684,\n",
       " 'diseases': 4555,\n",
       " 'bioterrorism': 2350,\n",
       " 'kvpbybglsr': 8621,\n",
       " 'graysondolan': 6608,\n",
       " 'me': 9535,\n",
       " 'kendall': 8400,\n",
       " 'jenner': 8071,\n",
       " 'nick': 10354,\n",
       " 'jonas': 8174,\n",
       " 'dating': 4153,\n",
       " 'quite': 12045,\n",
       " 'literally': 8995,\n",
       " 'explode': 5479,\n",
       " 'pfvzvpxqgr': 11315,\n",
       " 'always': 1431,\n",
       " 'tell': 14573,\n",
       " 'mom': 9889,\n",
       " 'bring': 2673,\n",
       " 'hold': 7155,\n",
       " 'her': 7027,\n",
       " 'cat': 3076,\n",
       " 'rt': 12816,\n",
       " 'startelegram': 13998,\n",
       " 'homeless': 7183,\n",
       " 'vulnerable': 15877,\n",
       " 'north': 10464,\n",
       " 'texas': 14630,\n",
       " 'heat': 6978,\n",
       " 'wave': 15994,\n",
       " 'k9airfq3ql': 8305,\n",
       " 'jdbtlymehy': 8056,\n",
       " 'nuclear': 10541,\n",
       " 'solar': 13722,\n",
       " 'power': 11599,\n",
       " 'japanese': 8020,\n",
       " 'fukushima': 6160,\n",
       " 'reactor': 12239,\n",
       " 'energy': 5217,\n",
       " 'japan': 8019,\n",
       " 'temperature': 14583,\n",
       " 'fuel': 6154,\n",
       " 'pool': 11543,\n",
       " 'ys3nmwwyvc': 16714,\n",
       " 'alpotnb7q3': 1414,\n",
       " 'least': 8810,\n",
       " 'taken': 14440,\n",
       " 'local': 9062,\n",
       " 'wlmsq3mtho': 16253,\n",
       " 'esteemed': 5343,\n",
       " 'journalist': 8195,\n",
       " 'recalls': 12284,\n",
       " 'tragic': 15052,\n",
       " 'effects': 5049,\n",
       " 'unaddressed': 15407,\n",
       " 'childhood': 3281,\n",
       " 'trauma': 15082,\n",
       " 'keithboykin': 8390,\n",
       " 'randallpinkston': 12160,\n",
       " 'pozarmy': 11604,\n",
       " 'gxq1auzb18': 6751,\n",
       " 'feel': 5688,\n",
       " 'panicking': 11100,\n",
       " 'results': 12516,\n",
       " 'back': 1969,\n",
       " 'alarmingly': 1345,\n",
       " 'calm': 2927,\n",
       " 'thunder': 14815,\n",
       " 'lightning': 8940,\n",
       " 'possible': 11571,\n",
       " 'pinpoint': 11389,\n",
       " 'foothill': 5962,\n",
       " 'forecast': 5971,\n",
       " 'ctijdpxabk': 3962,\n",
       " '40': 494,\n",
       " 'displaced': 4576,\n",
       " 'ocean': 10670,\n",
       " 'township': 15019,\n",
       " 'apartment': 1578,\n",
       " 'newyork': 10324,\n",
       " 'uelz59wvom': 15361,\n",
       " 'freddiedeboer': 6066,\n",
       " 'thucydiplease': 14813,\n",
       " 'rise': 12630,\n",
       " 'coates': 3500,\n",
       " 'charleston': 3224,\n",
       " 'massacre': 9453,\n",
       " 'walter': 15937,\n",
       " 'black': 2390,\n",
       " 'twitter': 15272,\n",
       " 'broadly': 2689,\n",
       " 'well': 16068,\n",
       " 'mathew_is_angry': 9472,\n",
       " 'z3ke_sk1': 16752,\n",
       " 'saladinahmed': 12949,\n",
       " 'died': 4479,\n",
       " 'horrible': 7229,\n",
       " 'deaths': 4212,\n",
       " 'trapped': 15080,\n",
       " 'ships': 13378,\n",
       " 'risk': 12633,\n",
       " 'destruction': 4398,\n",
       " 'fine': 5786,\n",
       " 'just': 8260,\n",
       " 'reality': 12258,\n",
       " 'training': 15058,\n",
       " 'falls': 5584,\n",
       " 'off': 10700,\n",
       " 'elevated': 5113,\n",
       " 'tracks': 15039,\n",
       " 'windstorm': 16195,\n",
       " 'jiomnrcygt': 8115,\n",
       " 'paramedic': 11121,\n",
       " 'ems': 5184,\n",
       " 'fears': 5676,\n",
       " 'missing': 9795,\n",
       " 'migrants': 9708,\n",
       " 'med': 9548,\n",
       " 'rescuers': 12467,\n",
       " 'search': 13155,\n",
       " 'survivors': 14309,\n",
       " 'boat': 2500,\n",
       " 'carrying': 3048,\n",
       " '6ds67xai5e': 711,\n",
       " 'derailed_benchmark': 4355,\n",
       " 'cool': 3736,\n",
       " 'paths': 11173,\n",
       " 'wonder': 16287,\n",
       " 'can': 2960,\n",
       " 'find': 5783,\n",
       " 'leaks': 8803,\n",
       " 'jobs': 8145,\n",
       " 'given': 6436,\n",
       " 'resque': 12500,\n",
       " 'too': 14958,\n",
       " 'new': 10302,\n",
       " 'ladies': 8675,\n",
       " 'tote': 14997,\n",
       " 'handbag': 6836,\n",
       " 'women': 16282,\n",
       " 'faux': 5642,\n",
       " 'leather': 8811,\n",
       " 'fashion': 5625,\n",
       " 'purse': 11893,\n",
       " 'y87gi3brlv': 16567,\n",
       " '1zbhvdcxzs': 261,\n",
       " 'raishimi33': 12147,\n",
       " 'sounds': 13789,\n",
       " 'plan': 11439,\n",
       " 'little': 9000,\n",
       " 'applaud': 1607,\n",
       " 'invading': 7810,\n",
       " 'iraq': 7857,\n",
       " 'catastrophic': 3081,\n",
       " 'mistake': 9803,\n",
       " 'diplomacy': 4510,\n",
       " 'needs': 10269,\n",
       " 'replace': 12441,\n",
       " 'constant': 3697,\n",
       " 'threat': 14785,\n",
       " 'war': 15947,\n",
       " 'israel': 7895,\n",
       " 'yqjpn3quux': 16704,\n",
       " 'related': 12374,\n",
       " 'threatens': 14788,\n",
       " 'europe': 5370,\n",
       " 'wk6b5z803o': 16248,\n",
       " 'marynmck': 9445,\n",
       " 'beyond': 2282,\n",
       " 'adorable': 1193,\n",
       " 'hope': 7213,\n",
       " 'won': 16286,\n",
       " 'been': 2190,\n",
       " 'noticed': 10491,\n",
       " 'devastation': 4417,\n",
       " 'coming': 3580,\n",
       " 'target': 14470,\n",
       " 'starbucks': 13987,\n",
       " 'closed': 3451,\n",
       " 'momneedscoffee': 9893,\n",
       " 'asap': 1727,\n",
       " 'iwontmakeit': 7930,\n",
       " 'redskins': 12326,\n",
       " 'wr': 16356,\n",
       " 'roberts': 12684,\n",
       " 'belly': 2230,\n",
       " 'bombed': 2518,\n",
       " 'teamstream': 14542,\n",
       " 'gbcvvevdty': 6312,\n",
       " 'allah': 1383,\n",
       " 'describes': 4365,\n",
       " 'piling': 11381,\n",
       " 'wealth': 16031,\n",
       " 'thinking': 14748,\n",
       " 'forever': 5979,\n",
       " 'hellfire': 7010,\n",
       " 'surah': 14283,\n",
       " 'humaza': 7324,\n",
       " 'reflect': 12338,\n",
       " 'loved': 9153,\n",
       " 'way': 15998,\n",
       " 'book': 2532,\n",
       " 'written': 16377,\n",
       " 'include': 7629,\n",
       " 'vantage': 15656,\n",
       " 'points': 11520,\n",
       " 'detkenlang': 4406,\n",
       " 'kindle': 8483,\n",
       " 'kcrnmjkj73': 8375,\n",
       " 'heartdisease': 6971,\n",
       " 'service': 13264,\n",
       " 'spending': 13853,\n",
       " 'half': 6820,\n",
       " 'budget': 2752,\n",
       " 'kzfigkeeva': 8638,\n",
       " 'forget': 5982,\n",
       " 'tragedy': 15051,\n",
       " 'gajtugaui7': 6254,\n",
       " 'liked': 8947,\n",
       " 'youtube': 16694,\n",
       " 'itsjustinstuart': 7912,\n",
       " 'mnkaji2q1n': 9848,\n",
       " 'range': 12168,\n",
       " 'mayhem': 9497,\n",
       " 'hungerarticles': 7339,\n",
       " 'nepal': 10287,\n",
       " 'rebuilding': 12279,\n",
       " 'livelihoods': 9010,\n",
       " 'quake': 12014,\n",
       " 'lrouwjmbix': 9177,\n",
       " 'suspected': 14315,\n",
       " 'serial': 13257,\n",
       " 'arsonist': 1706,\n",
       " 'arrested': 1696,\n",
       " 'calif': 2919,\n",
       " 'pzotpdgaki': 11928,\n",
       " 'chubbysquirrel_': 3341,\n",
       " 'hurricane_surge': 7357,\n",
       " 'very': 15713,\n",
       " 'true': 15173,\n",
       " '33333': 414,\n",
       " '9vw0uqqi1y': 982,\n",
       " 'marvel': 9442,\n",
       " 'vs': 15866,\n",
       " 'dc': 4177,\n",
       " 'avengers': 1884,\n",
       " 'battle': 2102,\n",
       " 'rockbottomradfm': 12693,\n",
       " 'challenges': 3191,\n",
       " 'tough': 15003,\n",
       " 'enough': 5238,\n",
       " 'rescuing': 12468,\n",
       " 'goes': 6510,\n",
       " 'engine': 5222,\n",
       " 'tyjxrfd3st': 15293,\n",
       " 'had': 6794,\n",
       " 'regular': 12363,\n",
       " 'coffees': 3516,\n",
       " 'rockstar': 12701,\n",
       " 'coffee': 3515,\n",
       " 'today': 14916,\n",
       " 'tired': 14871,\n",
       " 'butt': 2824,\n",
       " 'extraordinaire': 5510,\n",
       " 'nws': 10576,\n",
       " 'wth': 16392,\n",
       " 'rotating': 12766,\n",
       " 'huge': 7309,\n",
       " 'massive': 9456,\n",
       " 'violent': 15782,\n",
       " 'tornado': 14978,\n",
       " 'what': 16112,\n",
       " 'j3di85ist5': 7951,\n",
       " 'swb1192': 14334,\n",
       " 'nda': 10244,\n",
       " 'damage': 4087,\n",
       " 'ability': 1063,\n",
       " 'offer': 10705,\n",
       " 'services': 13265,\n",
       " 'future': 6186,\n",
       " 'prolly': 11763,\n",
       " 'anyway': 1565,\n",
       " 'ameenshaikh3': 1448,\n",
       " 'sir': 13509,\n",
       " 'wanted': 15944,\n",
       " 'make': 9350,\n",
       " 'point': 11518,\n",
       " 'sureshpprabhu': 14286,\n",
       " 'made': 9310,\n",
       " 'said': 12938,\n",
       " 'lying': 9239,\n",
       " 'sinkhole': 13505,\n",
       " 'swallows': 14327,\n",
       " 'brooklyn': 2701,\n",
       " 'intersection': 7793,\n",
       " 'ûò': 16931,\n",
       " '1ybe5mgzl4': 259,\n",
       " '7zog3dpdu9': 824,\n",
       " 'jacksonville': 7979,\n",
       " 'family': 5592,\n",
       " 'bands': 2023,\n",
       " 'together': 14928,\n",
       " 'memorial': 9593,\n",
       " 'planned': 11444,\n",
       " 'tilgurkv7z': 14847,\n",
       " '405': 499,\n",
       " 'southbound': 13797,\n",
       " 'coal': 3495,\n",
       " 'creek': 3886,\n",
       " 'pkwy': 11430,\n",
       " 'blocking': 2446,\n",
       " 'center': 3153,\n",
       " 'lane': 8707,\n",
       " 'im': 7563,\n",
       " 'feeling': 5690,\n",
       " 'attacked': 1808,\n",
       " '91jvycxxvi': 904,\n",
       " 'felt': 5704,\n",
       " 'namekians': 10176,\n",
       " 'played': 11456,\n",
       " 'when': 16120,\n",
       " 'planet': 11442,\n",
       " 'destroyed': 4394,\n",
       " 'acc': 1095,\n",
       " 'study': 14167,\n",
       " 'conducted': 3664,\n",
       " 'skims': 13559,\n",
       " 'morethan': 9935,\n",
       " '50': 588,\n",
       " 'population': 11552,\n",
       " 'kashmir': 8348,\n",
       " 'suffer': 14213,\n",
       " 'psychiatric': 11832,\n",
       " 'disorders': 4569,\n",
       " 'saf9mosksn': 12926,\n",
       " 'kashmirconflict': 8349,\n",
       " 'ideas': 7472,\n",
       " 'flattened': 5862,\n",
       " 'qfrawln4ba': 11968,\n",
       " 'eating': 4987,\n",
       " 'takis': 14443,\n",
       " 'rubbing': 12828,\n",
       " 'bleeding': 2421,\n",
       " 'tears': 14546,\n",
       " 'top': 14968,\n",
       " 'link': 8972,\n",
       " 'reddit': 12319,\n",
       " 'content': 3708,\n",
       " 'policy': 11530,\n",
       " ...}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punct_list = string.punctuation#.replace('#', '').replace('@', '')\n",
    "punct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "7PhQSWqcHhU8"
   },
   "outputs": [],
   "source": [
    "def contains_digit(s: str) -> bool:\n",
    "    # Проверка, содержит ли слово цифры\n",
    "    return any(map(str.isdigit, s))  \n",
    "\n",
    "def contains_punctuation(s: str) -> bool:\n",
    "    # Проверка, содержит ли слово пунктуацию\n",
    "    return any(map(lambda x: x in punct_list, s))\n",
    "\n",
    "def is_hashtag(s: str) -> bool:\n",
    "    # Проверка, является ли слово хэштегом\n",
    "    return s.startswith('#')\n",
    "\n",
    "def is_mention(s: str) -> bool:\n",
    "    # Проверка, является ли слово упоминанием\n",
    "    return s.startswith('@')\n",
    "\n",
    "def investigate_vocabulary(vocabulary):\n",
    "    # -- YOUR CODE HERE --\n",
    "    print('With digit:      ', sum(map(contains_digit, vocabulary.keys())))\n",
    "    print('With punctuation:', sum(map(contains_punctuation, vocabulary.keys())))\n",
    "    print('Hashtags:        ', sum(map(is_hashtag, vocabulary.keys())))\n",
    "    print('Mentions:        ', sum(map(is_mention, vocabulary.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With digit:       2\n",
      "With punctuation: 7\n",
      "Hashtags:         1\n",
      "Mentions:         3\n"
     ]
    }
   ],
   "source": [
    "dummy_vocab = {'th1nk' : 0,\n",
    "               'think333' : 1,\n",
    "               'think.' : 2,\n",
    "               'th!nk' : 3,\n",
    "               'th...nk' : 4,\n",
    "               '#think' : 5,\n",
    "               '@think' : 6,\n",
    "               '@thinking':7,\n",
    "               '@nothink' : 8,\n",
    "               'think' : 9}\n",
    "investigate_vocabulary(dummy_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "VpW8R_SuKR_l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With digit:       3663\n",
      "With punctuation: 300\n",
      "Hashtags:         0\n",
      "Mentions:         0\n"
     ]
    }
   ],
   "source": [
    "investigate_vocabulary(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfNLaxX93HvM"
   },
   "source": [
    "## Задание 6 (0.5 балла)\n",
    "\n",
    "Вспомним, что на семинаре по текстам мы узнали, что в nltk есть специальный токенизатор для текстов - TweetTokenizer. Попробуем применить CountVectorizer с этим токенизатором. Ответьте на все вопросы из предыдущего пункта для TweetTokenizer и сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "xnlRoXUS3HvM"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "# Чтобы узнать, какие параметры есть у этого токенайзера - используйте help(TweetTokenizer)\n",
    "# Для того, чтобы передать токенайзер в CountVectorizer используйте параметр tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(TweetTokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With digit:       3781\n",
      "With punctuation: 7136\n",
      "Hashtags:         1440\n",
      "Mentions:         1669\n"
     ]
    }
   ],
   "source": [
    "tweet_tokenizer = TweetTokenizer()\n",
    "vectorizer = CountVectorizer(tokenizer=tweet_tokenizer.tokenize)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "investigate_vocabulary(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из документации: Setting strip_handles to True, the tokenizer will remove Twitter handles (e.g. usernames). Setting reduce_len to True, repeated character sequences of length 3 or greater will be replaced with sequences of length 3.\n",
    "\n",
    "Поэтому установим эти параметры True, так как нам не важны usernames и повторяющиеся много раз символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "8lPMIf6UKccT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With digit:       3489\n",
      "With punctuation: 5476\n",
      "Hashtags:         1440\n",
      "Mentions:         9\n"
     ]
    }
   ],
   "source": [
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "vectorizer = CountVectorizer(tokenizer=tweet_tokenizer.tokenize)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "investigate_vocabulary(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wetr80-ILULV"
   },
   "source": [
    "**Сравнение:** В первую очередь заметим, что токенайзер по другому разделял # => у нас остались хэштеги, что очень хорошо, так как в них содержится тема твита. Слов с пунктуацией тоже стало больше, ведь мы знаем, что это достаточно распространенный метод цензуры текста в соц сетях, от таких слов тоже не стоит отказываться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_k_-i1x3HvM"
   },
   "source": [
    "## Задание 7 (2 балла)\n",
    "\n",
    "В scikit-learn мы можем оценивать процесс подсчета матрицы через CountVectorizer. У CountVectorizer, как и у других наследников \\_VectorizerMixin, есть аргумент tokenizer и preprocessor. preprocessor применится в самом начале к каждой строке вашего датасета, tokenizer же должен принять строку и вернуть токены.\n",
    "Давайте напишем кастомный токенайзер, которые сделает все, что нам нужно: \n",
    "\n",
    "0. Приведет все буквы к нижнему регистру\n",
    "1. Разобьет текст на токены с помощью TweetTokenizer из пакета nltk\n",
    "2. Удалит все токены содержащие не латинские буквы, кроме смайликов (будем считать ими токены содержащие только пунктуацию и, как минимум, одну скобочку) и хэштегов, которые после начальной # содержат только латинские буквы.\n",
    "3. Удалит все токены, которые перечислены в nltk.corpus.stopwords.words('english')\n",
    "4. Проведет стемминг с помощью SnowballStemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import ascii_letters\n",
    "ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "snowball = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "qhwmi7DEMD25"
   },
   "outputs": [],
   "source": [
    "def contains_only_latin_letters(s: str) -> bool:\n",
    "    # Проверка, содержит ли слово только латинские буквы\n",
    "    return all(map(lambda c: c in ascii_letters, s))\n",
    "\n",
    "def is_emoji(s: str) -> bool:\n",
    "    # Проверка, является ли слово смайликом\n",
    "    punct_flag = all(map(lambda c: c in punct_list, s))\n",
    "    bracket_flag = any([s.find(c) != -1 for c in ['(', ')', '[', ']', '{', '}']])\n",
    "    return punct_flag and bracket_flag\n",
    "\n",
    "def is_hashtag(s: str) -> bool:\n",
    "    # Проверка, является ли слово хэштегом\n",
    "    return s.startswith('#') and contains_only_latin_letters(s[1:])\n",
    "\n",
    "def custom_tokenizer(s: str) -> List[str]:    \n",
    "    # Кастомный токенайзер\n",
    "    tokens = tokenizer.tokenize(s.lower())\n",
    "    tokens = list(filter(lambda x: contains_only_latin_letters(x) or is_emoji(x) or is_hashtag(x), tokens))\n",
    "    tokens = list(filter(lambda x: x not in nltk.corpus.stopwords.words('english'), tokens))\n",
    "    return list(map(snowball.stem, tokens))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'paint', ':-)', '#art']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer('She LOVES painting :-) #art')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S_-ThAf5It4"
   },
   "source": [
    "Продемонстрируйте работу вашей функции на первых десяти текстах в обучающей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "A1fh3_itPz7D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================1==============================\n",
      "Initial text: Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "Tokenized text: ['ash', 'australia', 'collaps', 'trent', 'bridg', 'among', 'worst', 'histori', 'england', 'bundl', 'australia']\n",
      "==============================2==============================\n",
      "Initial text: GREAT MICHIGAN TECHNIQUE CAMP\n",
      "B1G THANKS TO @bmurph1019 \n",
      "@hail_Youtsey . @termn8r13 \n",
      "#GoBlue #WrestleOn http://t.co/OasKgki6Qj\n",
      "Tokenized text: ['great', 'michigan', 'techniqu', 'camp', 'thank', '#goblu', '#wrestleon']\n",
      "==============================3==============================\n",
      "Initial text: CNN: Tennessee movie theater shooting suspect killed by police http://t.co/dI8ElZsWNR\n",
      "Tokenized text: ['cnn', 'tennesse', 'movi', 'theater', 'shoot', 'suspect', 'kill', 'polic']\n",
      "==============================4==============================\n",
      "Initial text: Still rioting in a couple of hours left until I have to be up for class.\n",
      "Tokenized text: ['still', 'riot', 'coupl', 'hour', 'left', 'class']\n",
      "==============================5==============================\n",
      "Initial text: Crack in the path where I wiped out this morning during beach run. Surface wounds on left elbow and right knee. http://t.co/yaqRSximph\n",
      "Tokenized text: ['crack', 'path', 'wipe', 'morn', 'beach', 'run', 'surfac', 'wound', 'left', 'elbow', 'right', 'knee']\n",
      "==============================6==============================\n",
      "Initial text: Experts in France begin examining airplane debris found on Reunion Island: French air accident experts on... http://t.co/TagZbcXFj0 #MLB\n",
      "Tokenized text: ['expert', 'franc', 'begin', 'examin', 'airplan', 'debri', 'found', 'reunion', 'island', 'french', 'air', 'accid', 'expert', '#mlb']\n",
      "==============================7==============================\n",
      "Initial text: 'I came to kill Indians...for FUN': Video of smirking and remorseless Pakistani killer shows him boasting. http://t.co/FPjLwOXKlg\n",
      "Tokenized text: ['came', 'kill', 'indian', 'fun', 'video', 'smirk', 'remorseless', 'pakistani', 'killer', 'show', 'boast']\n",
      "==============================8==============================\n",
      "Initial text: @JohnsonTionne except idk them?? it's really burning ??????\n",
      "Tokenized text: ['except', 'idk', 'realli', 'burn']\n",
      "==============================9==============================\n",
      "Initial text: destroy the house\n",
      "Tokenized text: ['destroy', 'hous']\n",
      "==============================10==============================\n",
      "Initial text: Police Officer Wounded Suspect Dead After Exchanging Shots http://t.co/XxFk4KHbIw\n",
      "Tokenized text: ['polic', 'offic', 'wound', 'suspect', 'dead', 'exchang', 'shot']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    text = train.text.tolist()[i]\n",
    "    print('='*30 + str(i+1)+ '='*30)\n",
    "    print(f'Initial text: {text}')\n",
    "    print(f'Tokenized text: {custom_tokenizer(text)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5lNZ4tb3HvN"
   },
   "source": [
    "## Задание 8 (1 балл)\n",
    "\n",
    "1. Примените CountVectorizer с реализованным выше токенизатором к обучающим и тестовым выборкам.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "LDqixz7QQEbn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=custom_tokenizer)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "y_train = train.target.tolist()\n",
    "\n",
    "X_test = vectorizer.transform(test.text.tolist())\n",
    "y_test = test.target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 9258)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "LDqixz7QQEbn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With digit:       0\n",
      "With punctuation: 1309\n",
      "Hashtags:         1297\n",
      "Mentions:         0\n"
     ]
    }
   ],
   "source": [
    "investigate_vocabulary(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcetwuEi5ds9"
   },
   "source": [
    "2. Обучите LogisticRegression на полученных признаках.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "BVj03QV2QbWl"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ch6uz2P5e-T"
   },
   "source": [
    "3. Посчитайте метрику f1-score на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osyC0pdT3cSD",
    "outputId": "cd957d5f-5118-4b7f-d7ba-01bb5a524086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7513691128148959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f'F1 score: {f1_score(y_test, logreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFIEYOMZ3HvN"
   },
   "source": [
    "## Задание 9 (1 балл)\n",
    "\n",
    "1. Повторите 8 задание, но с tf-idf векторизатором. Как изменилось качество?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDqs61hl3ve3",
    "outputId": "fdd72125-dfde-4183-d614-3b0bc9002ada"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7444507683551508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "y_train = train.target.tolist()\n",
    "\n",
    "X_test = vectorizer.transform(test.text.tolist())\n",
    "y_test = test.target.tolist()\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f'F1 score: {f1_score(y_test, logreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 9258)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXaNclTZSFjO"
   },
   "source": [
    "1. **Ответ:** ну качество чуть чуть упало"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPtk0lCA5POY"
   },
   "source": [
    "2. Мы можем еще сильнее уменьшить размер нашей матрицы, если отбросим значения df близкие к единице. Скорее всего такие слова не несут много информации о категории, так как встречаются достаточно часто. Ограничьте максимальный df в параметрах TfIdfVectorizer, поставьте верхнюю границу равную 0.9. Как изменился размер матрицы, как изменилось качество?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EU-MRXyRSHLm",
    "outputId": "6b5353a8-5f3b-4220-fcd4-64eecfe20054"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7444507683551508\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=0.9)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "y_train = train.target.tolist()\n",
    "\n",
    "X_test = vectorizer.transform(test.text.tolist())\n",
    "y_test = test.target.tolist()\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f'F1 score: {f1_score(y_test, logreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "z1TkO9HeSTJ9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5329, 9258)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Two_O3rSVmh"
   },
   "source": [
    "2. **Ответ:** Размер матрицы никак не уменьшился => качество модели такое же. 0.9 все еще многовато, похоже у всех слов пропорция документов меньше этого числа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhyjbI5X5QnG"
   },
   "source": [
    "3. Также мы можем уменьшить размер матрицы, удаляя слова со слишком маленьким df. Удалось ли добиться улучшения качества? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mNpIxv6SfKc",
    "outputId": "607ec22e-1fdb-4c29-bbc4-6447ed266349"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7025813692480359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5329, 322)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=0.9, min_df=0.005)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "y_train = train.target.tolist()\n",
    "\n",
    "X_test = vectorizer.transform(test.text.tolist())\n",
    "y_test = test.target.tolist()\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f'F1 score: {f1_score(y_test, logreg.predict(X_test))}')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imeD8skxSqdg"
   },
   "source": [
    "3. **Ответ:** словарь ооочень сильно уменьшился, учитывая, что min_df=0.005 (до этого я пробовал 0.1, 0.01 и слов не оставалось), значит, что все слова достаточно редки. Плюсом из-за такого сильно сокращения словаря итоговый скор упал, однако, всего на 5 процентов. Это говорит нам о том, что мы потеряли не слишком много важных слов. Наверное, оптимальным размером словаря будет 1к"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l1sx4nB3HvN"
   },
   "source": [
    "## Задание 10 (1 балл)\n",
    "\n",
    "Еще один популяпный трюк, который позволит уменьшить количество признаков называется hashing trick. Его суть в том, то мы случайно группируем признаки ииии  ..... складываем их! А потом удаляем исходные признаки. В итоге все наши признаки это просто суммы исходных. Звучит странно, но это отлично работает. Давайте проверим этот трюк в нашем сеттинге.\n",
    "Также при таком подходе вам не нужно хранить словарь token->index, что тоже иногда полезно.\n",
    "\n",
    "1. Повторите задание 8 с HashingVectorizer, укажите количество фичей равное 5000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qSoW894RXxz",
    "outputId": "720818f4-f774-4273-bb10-918ecc72ef44"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qSoW894RXxz",
    "outputId": "720818f4-f774-4273-bb10-918ecc72ef44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7233065442020665\n"
     ]
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(tokenizer=custom_tokenizer, n_features=5000)\n",
    "X_train = vectorizer.fit_transform(train.text.tolist())\n",
    "y_train = train.target.tolist()\n",
    "\n",
    "X_test = vectorizer.transform(test.text.tolist())\n",
    "y_test = test.target.tolist()\n",
    "\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "print(f'F1 score: {f1_score(y_test, logreg.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1C3I4ceg6AG-"
   },
   "source": [
    "2. Какой из подходов показал самый высокий результат?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bIfyVlOS9Lu"
   },
   "source": [
    "2. **Ответ:** Ну судя по метрике, лучше всего оказался подход с CountVectorizer'ом, однако, тут мы проигрываем по памяти, так как слишком много фичей. Чуть хуже справился tf-idf, в нем мы можем подрезать словарь по важности слов и не сильно проиграть в качестве, зато экономим память. Между ними вписался HashingVectorizer, который тоже неплохо отработал с кол-ом фичей в 5к"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zylJ6l0R3HvN"
   },
   "source": [
    "## Задание 11 (1 балл)\n",
    "\n",
    "В этом задании нужно добиться f1 меры хотя в 0.75 на тестовых данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSTVApFeS-OY"
   },
   "source": [
    "**Ответ**: ну в задании 8 я уже добился этого...вроде я автоматом получаю балл здесь)) Но вообще, если бы я хотел еще попытаться повысить скор, я бы начал эксперементировать с токенайзером и параметрами векторайзеров в кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YlLemInT3HvL",
    "A8CPBUal3HvL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
